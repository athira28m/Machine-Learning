{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ecd5bf6",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cb12cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d2f38b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85382c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\athir\\data_sets\\ML\\Assg_community\\data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1fd24",
   "metadata": {},
   "source": [
    "# step 3: data cleaning, data wrangling, data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92408646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "389a249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0\n",
       "diagnosis                    0\n",
       "radius_mean                  0\n",
       "texture_mean                 0\n",
       "perimeter_mean               0\n",
       "area_mean                    0\n",
       "smoothness_mean              0\n",
       "compactness_mean             0\n",
       "concavity_mean               0\n",
       "concave points_mean          0\n",
       "symmetry_mean                0\n",
       "fractal_dimension_mean       0\n",
       "radius_se                    0\n",
       "texture_se                   0\n",
       "perimeter_se                 0\n",
       "area_se                      0\n",
       "smoothness_se                0\n",
       "compactness_se               0\n",
       "concavity_se                 0\n",
       "concave points_se            0\n",
       "symmetry_se                  0\n",
       "fractal_dimension_se         0\n",
       "radius_worst                 0\n",
       "texture_worst                0\n",
       "perimeter_worst              0\n",
       "area_worst                   0\n",
       "smoothness_worst             0\n",
       "compactness_worst            0\n",
       "concavity_worst              0\n",
       "concave points_worst         0\n",
       "symmetry_worst               0\n",
       "fractal_dimension_worst      0\n",
       "Unnamed: 32                569\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a00f259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           0.0\n",
       "diagnosis                    0.0\n",
       "radius_mean                  0.0\n",
       "texture_mean                 0.0\n",
       "perimeter_mean               0.0\n",
       "area_mean                    0.0\n",
       "smoothness_mean              0.0\n",
       "compactness_mean             0.0\n",
       "concavity_mean               0.0\n",
       "concave points_mean          0.0\n",
       "symmetry_mean                0.0\n",
       "fractal_dimension_mean       0.0\n",
       "radius_se                    0.0\n",
       "texture_se                   0.0\n",
       "perimeter_se                 0.0\n",
       "area_se                      0.0\n",
       "smoothness_se                0.0\n",
       "compactness_se               0.0\n",
       "concavity_se                 0.0\n",
       "concave points_se            0.0\n",
       "symmetry_se                  0.0\n",
       "fractal_dimension_se         0.0\n",
       "radius_worst                 0.0\n",
       "texture_worst                0.0\n",
       "perimeter_worst              0.0\n",
       "area_worst                   0.0\n",
       "smoothness_worst             0.0\n",
       "compactness_worst            0.0\n",
       "concavity_worst              0.0\n",
       "concave points_worst         0.0\n",
       "symmetry_worst               0.0\n",
       "fractal_dimension_worst      0.0\n",
       "Unnamed: 32                100.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0621e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('Unnamed: 32',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf98729e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id column also unnecessary. Hence we can drop id column.\n",
    "\n",
    "data = data.drop('id',axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c79152e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2780166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0          0.4601                  0.11890          M  \n",
       "1          0.2750                  0.08902          M  \n",
       "2          0.3613                  0.08758          M  \n",
       "3          0.6638                  0.17300          M  \n",
       "4          0.2364                  0.07678          M  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[ 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "             'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "             'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "             'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "             'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "             'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "             'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "             'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "             'symmetry_worst', 'fractal_dimension_worst','diagnosis']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f5327",
   "metadata": {},
   "source": [
    "# Create a Numerical pipeline for preprocessing all the numerical variables present in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd443c64",
   "metadata": {},
   "source": [
    "## step 1: Import all the libraries and functins needed for data preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cba8558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SimpleImputer(strategy='median')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for numerical data\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "sim_imp = SimpleImputer(strategy = 'median')\n",
    "sim_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cd232fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for feature scaling\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "mms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a8e2f",
   "metadata": {},
   "source": [
    "## step 2: Mention the steps needed to perform automation and store it in the 'steps' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba4b87cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Missing value treatment', SimpleImputer(strategy='median')),\n",
       " ('Numerical scaling', MinMaxScaler())]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_steps = [('Missing value treatment',sim_imp),('Numerical scaling',mms)]\n",
    "num_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b47110b",
   "metadata": {},
   "source": [
    "## step 3: Import pipeline function from sklearn and create pipeline with the \"steps\" variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23f047e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;Missing value treatment&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;Numerical scaling&#x27;, MinMaxScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Missing value treatment&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;Numerical scaling&#x27;, MinMaxScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('Missing value treatment', SimpleImputer(strategy='median')),\n",
       "                ('Numerical scaling', MinMaxScaler())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "num_pipe = Pipeline(num_steps)\n",
    "num_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e42c684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      " 30  diagnosis                569 non-null    object \n",
      "dtypes: float64(30), object(1)\n",
      "memory usage: 137.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a639ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                0.186816  ...       0.123934         0.506948    0.341575   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0        0.598462                 0.418864          M  \n",
       "1        0.233590                 0.222878          M  \n",
       "2        0.403706                 0.213433          M  \n",
       "3        1.000000                 0.773711          M  \n",
       "4        0.157500                 0.142595          M  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[[ 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "             'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "             'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "             'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "             'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "             'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "             'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "             'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "             'symmetry_worst', 'fractal_dimension_worst']] = num_pipe.fit_transform(data[[ 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
    "             'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
    "             'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
    "             'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
    "             'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
    "             'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
    "             'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
    "             'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
    "             'symmetry_worst', 'fractal_dimension_worst']])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f3fe4",
   "metadata": {},
   "source": [
    "## Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c6d508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.428813</td>\n",
       "      <td>0.678668</td>\n",
       "      <td>0.566490</td>\n",
       "      <td>0.526948</td>\n",
       "      <td>0.296055</td>\n",
       "      <td>0.571462</td>\n",
       "      <td>0.690358</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.132056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383262</td>\n",
       "      <td>0.576174</td>\n",
       "      <td>0.452664</td>\n",
       "      <td>0.461137</td>\n",
       "      <td>0.178527</td>\n",
       "      <td>0.328035</td>\n",
       "      <td>0.761512</td>\n",
       "      <td>0.097575</td>\n",
       "      <td>0.105667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.622320</td>\n",
       "      <td>0.626987</td>\n",
       "      <td>0.604036</td>\n",
       "      <td>0.474019</td>\n",
       "      <td>0.407782</td>\n",
       "      <td>0.257714</td>\n",
       "      <td>0.337395</td>\n",
       "      <td>0.486630</td>\n",
       "      <td>0.349495</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699094</td>\n",
       "      <td>0.520892</td>\n",
       "      <td>0.379915</td>\n",
       "      <td>0.300007</td>\n",
       "      <td>0.159997</td>\n",
       "      <td>0.256789</td>\n",
       "      <td>0.559450</td>\n",
       "      <td>0.198502</td>\n",
       "      <td>0.074315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.455251</td>\n",
       "      <td>0.621238</td>\n",
       "      <td>0.445788</td>\n",
       "      <td>0.303118</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>0.254340</td>\n",
       "      <td>0.216753</td>\n",
       "      <td>0.263519</td>\n",
       "      <td>0.267677</td>\n",
       "      <td>0.137321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.589019</td>\n",
       "      <td>0.379949</td>\n",
       "      <td>0.230731</td>\n",
       "      <td>0.282177</td>\n",
       "      <td>0.273705</td>\n",
       "      <td>0.271805</td>\n",
       "      <td>0.487285</td>\n",
       "      <td>0.128721</td>\n",
       "      <td>0.151909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0.644564</td>\n",
       "      <td>0.663510</td>\n",
       "      <td>0.665538</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.790197</td>\n",
       "      <td>0.823336</td>\n",
       "      <td>0.755467</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>0.425442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730277</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.402035</td>\n",
       "      <td>0.619626</td>\n",
       "      <td>0.815758</td>\n",
       "      <td>0.749760</td>\n",
       "      <td>0.910653</td>\n",
       "      <td>0.497142</td>\n",
       "      <td>0.452315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.501522</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074351</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.187026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489072</td>\n",
       "      <td>0.043578</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>0.124084</td>\n",
       "      <td>0.036043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257441</td>\n",
       "      <td>0.100682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0       0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1       0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2       0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3       0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4       0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564     0.690000      0.428813        0.678668   0.566490         0.526948   \n",
       "565     0.622320      0.626987        0.604036   0.474019         0.407782   \n",
       "566     0.455251      0.621238        0.445788   0.303118         0.288165   \n",
       "567     0.644564      0.663510        0.665538   0.475716         0.588336   \n",
       "568     0.036869      0.501522        0.028540   0.015907         0.000000   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0            0.792037        0.703140             0.731113       0.686364   \n",
       "1            0.181768        0.203608             0.348757       0.379798   \n",
       "2            0.431017        0.462512             0.635686       0.509596   \n",
       "3            0.811361        0.565604             0.522863       0.776263   \n",
       "4            0.347893        0.463918             0.518390       0.378283   \n",
       "..                ...             ...                  ...            ...   \n",
       "564          0.296055        0.571462             0.690358       0.336364   \n",
       "565          0.257714        0.337395             0.486630       0.349495   \n",
       "566          0.254340        0.216753             0.263519       0.267677   \n",
       "567          0.790197        0.823336             0.755467       0.675253   \n",
       "568          0.074351        0.000000             0.000000       0.266162   \n",
       "\n",
       "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
       "0                  0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                  0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                  0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                  1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                  0.186816  ...       0.123934         0.506948    0.341575   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                0.132056  ...       0.383262         0.576174    0.452664   \n",
       "565                0.113100  ...       0.699094         0.520892    0.379915   \n",
       "566                0.137321  ...       0.589019         0.379949    0.230731   \n",
       "567                0.425442  ...       0.730277         0.668310    0.402035   \n",
       "568                0.187026  ...       0.489072         0.043578    0.020497   \n",
       "\n",
       "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0            0.601136           0.619292         0.568610   \n",
       "1            0.347553           0.154563         0.192971   \n",
       "2            0.483590           0.385375         0.359744   \n",
       "3            0.915472           0.814012         0.548642   \n",
       "4            0.437364           0.172415         0.319489   \n",
       "..                ...                ...              ...   \n",
       "564          0.461137           0.178527         0.328035   \n",
       "565          0.300007           0.159997         0.256789   \n",
       "566          0.282177           0.273705         0.271805   \n",
       "567          0.619626           0.815758         0.749760   \n",
       "568          0.124084           0.036043         0.000000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0                0.912027        0.598462                 0.418864          1  \n",
       "1                0.639175        0.233590                 0.222878          1  \n",
       "2                0.835052        0.403706                 0.213433          1  \n",
       "3                0.884880        1.000000                 0.773711          1  \n",
       "4                0.558419        0.157500                 0.142595          1  \n",
       "..                    ...             ...                      ...        ...  \n",
       "564              0.761512        0.097575                 0.105667          1  \n",
       "565              0.559450        0.198502                 0.074315          1  \n",
       "566              0.487285        0.128721                 0.151909          1  \n",
       "567              0.910653        0.497142                 0.452315          1  \n",
       "568              0.000000        0.257441                 0.100682          0  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'M':1, 'B':0}\n",
    "data['diagnosis'] = data['diagnosis'].replace(dic)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10541b3a",
   "metadata": {},
   "source": [
    "## separate the data into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43039526",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('diagnosis',axis = 1)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef78c52",
   "metadata": {},
   "source": [
    "# split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ddb0da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state =0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c636c",
   "metadata": {},
   "source": [
    "# Perform 10 Fold Cross Validation on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c7bb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits = 10)\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f0905a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _BaseKFold.split at 0x000001AC5DB370D0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf.split(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea37463f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
       "          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
       "         109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
       "         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
       "         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
       "         187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "         213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "         51, 52, 53, 54, 55, 56])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56, 114, 115, 116, 117, 118, 119, 120, 121,\n",
       "         122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134,\n",
       "         135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "         148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "         161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
       "         187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "         213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([ 57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,\n",
       "          83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,\n",
       "          96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108,\n",
       "         109, 110, 111, 112, 113])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 171, 172, 173,\n",
       "         174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186,\n",
       "         187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199,\n",
       "         200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "         213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "         127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
       "         140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152,\n",
       "         153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165,\n",
       "         166, 167, 168, 169, 170])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
       "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
       "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
       "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,\n",
       "         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "         197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
       "         210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "         223, 224, 225, 226, 227])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 285, 286, 287, 288, 289, 290,\n",
       "         291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303,\n",
       "         304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316,\n",
       "         317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329,\n",
       "         330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240,\n",
       "         241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,\n",
       "         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266,\n",
       "         267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
       "         280, 281, 282, 283, 284])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 342,\n",
       "         343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355,\n",
       "         356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368,\n",
       "         369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
       "         382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394,\n",
       "         395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
       "         298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310,\n",
       "         311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,\n",
       "         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336,\n",
       "         337, 338, 339, 340, 341])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "         299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 399, 400, 401, 402, 403, 404, 405, 406, 407,\n",
       "         408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420,\n",
       "         421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "         434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446,\n",
       "         447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354,\n",
       "         355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
       "         368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380,\n",
       "         381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393,\n",
       "         394, 395, 396, 397, 398])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "         299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 395, 396, 397, 398, 456, 457, 458, 459,\n",
       "         460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472,\n",
       "         473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485,\n",
       "         486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498,\n",
       "         499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511,\n",
       "         512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411,\n",
       "         412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424,\n",
       "         425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
       "         438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
       "         451, 452, 453, 454, 455])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "         299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "         416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "         429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "         455, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524,\n",
       "         525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537,\n",
       "         538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550,\n",
       "         551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
       "         564, 565, 566, 567, 568]),\n",
       "  array([456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468,\n",
       "         469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481,\n",
       "         482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494,\n",
       "         495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
       "         508, 509, 510, 511, 512])),\n",
       " (array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "          78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "          91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "         104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "         130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "         143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "         169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "         182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "         195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "         208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "         221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "         234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "         247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n",
       "         260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n",
       "         273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n",
       "         286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n",
       "         299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
       "         312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n",
       "         325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n",
       "         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n",
       "         351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "         364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n",
       "         377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n",
       "         390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n",
       "         403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n",
       "         416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428,\n",
       "         429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441,\n",
       "         442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454,\n",
       "         455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467,\n",
       "         468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480,\n",
       "         481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
       "         494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506,\n",
       "         507, 508, 509, 510, 511, 512]),\n",
       "  array([513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
       "         526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538,\n",
       "         539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551,\n",
       "         552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564,\n",
       "         565, 566, 567, 568]))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(kf.split(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cca780",
   "metadata": {},
   "source": [
    "# Determine whether Logistic Regression or KNeighborsClassifier suits better on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02d819e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply logistic regression and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73df41a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "edfef802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88624bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lr = lr.predict(x_test)\n",
    "y_pred_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6007196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5852a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply KNeighborsClassifier and check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7053519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd58876d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2868e00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knc = knc.predict(x_test)\n",
    "y_pred_knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f52d1381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_knc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93540090",
   "metadata": {},
   "source": [
    "#### Both logistic regression and KNeighborsClassifier giving an accuracy of 96.49%. hence both the methods are performing well in this data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f33e77",
   "metadata": {},
   "source": [
    "# Apply 10 Fold Cross Validation and find out the best accuracy using Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ae691e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "821c74af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.92982456, 0.98245614, 0.98245614, 0.96491228,\n",
       "       0.98245614, 0.94736842, 1.        , 0.98245614, 0.94642857])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afadbfe6",
   "metadata": {},
   "source": [
    "- 1st and 8th train-test sets are giving the accuracy of 100% on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7d5be",
   "metadata": {},
   "source": [
    "# Apply 10 Fold Cross Validation and find out the best accuracy using K Neighbors Classification Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff4f96b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knc = KNeighborsClassifier()\n",
    "knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4aa14851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96491228, 0.94736842, 0.92982456, 0.98245614, 1.        ,\n",
       "       0.98245614, 0.92982456, 0.98245614, 0.96491228, 0.98214286])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knc,x,y,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5160d",
   "metadata": {},
   "source": [
    "- 5th train-test set is giving an accuracy of 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1461ff2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
